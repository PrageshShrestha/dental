{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv12 Object Detection Training, Evaluation, and Inference\n",
    "\n",
    "This notebook provides a professional pipeline for training, evaluating, and performing inference with a YOLOv12 model. It includes:\n",
    "- Structured logging to track progress and errors\n",
    "- Training and validation metrics visualization (loss, mAP) using Matplotlib from `results.csv`\n",
    "- Comprehensive evaluation on validation and test sets\n",
    "- Results storage in CSV format\n",
    "- Model checkpointing and saving as `yolo12_trained.pt`\n",
    "- Inference on a user-specified image with results overlaid and displayed in a new window\n",
    "- Option to load a pre-trained model (`yolo12_trained.pt`) for inference\n",
    "\n",
    "## Prerequisites\n",
    "- Ensure `prepared_data.yaml` is correctly formatted with train/val/test paths for training/evaluation.\n",
    "- Install required libraries: `pip install ultralytics matplotlib seaborn pandas pyyaml pillow`.\n",
    "- GPU recommended for faster training/inference (set `device='cpu'` if GPU is unavailable).\n",
    "- For inference, provide a path to a test image (e.g., `test_image.jpg`) in the inference cell.\n",
    "- If using a pre-trained model, ensure `yolo12_trained.pt` exists in the specified path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "from PIL import Image\n",
    "import subprocess\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(f'training_log_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Define functions for loading data configuration, plotting training metrics, evaluating the model, and performing inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_config(data_yaml):\n",
    "    \"\"\"Load and validate the data configuration file.\"\"\"\n",
    "    try:\n",
    "        with open(data_yaml, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        logger.info(f\"Loaded data configuration from {data_yaml}\")\n",
    "        return config\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load data configuration: {e}\")\n",
    "        raise\n",
    "\n",
    "def plot_training_metrics(save_dir):\n",
    "    \"\"\"Plot training and validation metrics from results.csv.\"\"\"\n",
    "    try:\n",
    "        # Load metrics from results.csv\n",
    "        results_csv_path = os.path.join(save_dir, 'yolo12_train', 'results.csv')\n",
    "        if not os.path.exists(results_csv_path):\n",
    "            logger.error(f\"Results CSV not found at {results_csv_path}\")\n",
    "            return\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(results_csv_path)\n",
    "        \n",
    "        # Strip whitespace from column names\n",
    "        df.columns = df.columns.str.strip()\n",
    "        \n",
    "        # Create plots\n",
    "        plt.style.use('seaborn')\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Loss plot\n",
    "        ax1.plot(df['train/box_loss'], label='Train Box Loss', color='blue')\n",
    "        ax1.plot(df['val/box_loss'], label='Validation Box Loss', color='orange')\n",
    "        ax1.set_title('Training and Validation Box Loss')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # mAP plot\n",
    "        ax2.plot(df['metrics/mAP50(B)'], label='mAP@50', color='green')\n",
    "        ax2.plot(df['metrics/mAP50-95(B)'], label='mAP@50:95', color='red')\n",
    "        ax2.set_title('Validation mAP Metrics')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('mAP')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plot_path = os.path.join(save_dir, 'training_metrics.png')\n",
    "        plt.savefig(plot_path)\n",
    "        plt.show()\n",
    "        logger.info(f\"Training metrics plot saved to {plot_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to plot training metrics: {e}\")\n",
    "\n",
    "def evaluate_model(model, data_yaml, split='test'):\n",
    "    \"\"\"Evaluate the model on the specified dataset split.\"\"\"\n",
    "    logger.info(f\"Evaluating model on {split} dataset...\")\n",
    "    results = model.val(data=data_yaml, split=split)\n",
    "    metrics = {\n",
    "        'mAP50': results.box.map50,\n",
    "        'mAP50-95': results.box.map,\n",
    "        'Precision': results.box.p,\n",
    "        'Recall': results.box.r\n",
    "    }\n",
    "    logger.info(f\"{split.capitalize()} Metrics: {metrics}\")\n",
    "    return metrics\n",
    "\n",
    "def perform_inference(model, image_path, save_dir):\n",
    "    \"\"\"Perform inference on a single image and display results in a new window.\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Performing inference on {image_path}\")\n",
    "        # Run inference and save annotated image\n",
    "        results = model.predict(image_path, save=True, save_dir=save_dir)\n",
    "        \n",
    "        # Get the path to the saved annotated image\n",
    "        result_image_path = os.path.join(save_dir, os.path.basename(image_path))\n",
    "        if not os.path.exists(result_image_path):\n",
    "            logger.error(f\"Annotated image not found at {result_image_path}\")\n",
    "            return\n",
    "        \n",
    "        # Open the annotated image in the system's default image viewer\n",
    "        Image.open(result_image_path).show()\n",
    "        logger.info(f\"Inference result saved and displayed from {result_image_path}\")\n",
    "        \n",
    "        # Log detection details\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            logger.info(f\"Detected {len(boxes)} objects: {boxes.cls}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Inference failed: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation Pipeline\n",
    "\n",
    "Configure and run the training pipeline (if no pre-trained model is found), followed by evaluation. If a pre-trained model exists, skip training and proceed to inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 14:05:02,620 - INFO - No pre-trained model found at yolo12_trained.pt. Starting training...\n",
      "2025-09-24 14:05:02,631 - INFO - Loaded data configuration from prepared_data.yaml\n",
      "2025-09-24 14:05:02,631 - INFO - Loading YOLO model: yolo12n.pt\n",
      "2025-09-24 14:05:02,679 - INFO - Starting training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.203  Python-3.11.9 torch-2.10.0.dev20250923+cu128 CUDA:0 (NVIDIA GeForce RTX 5060 Ti, 16311MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=6, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=prepared_data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1200, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo12n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo12_train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/train/exp_20250924_140502, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\user\\Desktop\\dental\\runs\\train\\exp_20250924_140502\\yolo12_train, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=41\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  2    180864  ultralytics.nn.modules.block.A2C2f           [128, 128, 2, True, 4]        \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 1]        \n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  1     86912  ultralytics.nn.modules.block.A2C2f           [384, 128, 1, False, -1]      \n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  1     24000  ultralytics.nn.modules.block.A2C2f           [256, 64, 1, False, -1]       \n",
      " 15                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     74624  ultralytics.nn.modules.block.A2C2f           [192, 128, 1, False, -1]      \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 21        [14, 17, 20]  1    438667  ultralytics.nn.modules.head.Detect           [41, [64, 128, 256]]          \n",
      "YOLOv12n summary: 272 layers, 2,576,043 parameters, 2,576,027 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 640/691 items from pretrained weights\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "WARNING imgsz=[1200] must be multiple of max stride 32, updating to [1216]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 90.828.4 MB/s, size: 568.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\user\\Desktop\\dental\\real_dataset\\train\\labels... 348 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 348/348 1.5Kit/s 0.2s<0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\user\\Desktop\\dental\\real_dataset\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 37.911.8 MB/s, size: 502.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\user\\Desktop\\dental\\real_dataset\\valid\\labels... 90 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 90/90 650.3it/s 0.1s0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\user\\Desktop\\dental\\real_dataset\\valid\\labels.cache\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "model_name = \"yolo12n.pt\"\n",
    "pretrained_model_path = \"yolo12_trained.pt\"\n",
    "data_yaml = \"prepared_data.yaml\"\n",
    "epochs = 100\n",
    "img_size = 1200\n",
    "batch_size = 3\n",
    "device = 0  # Set to 'cpu' if GPU is unavailable\n",
    "save_dir = f'runs/train/exp_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "\n",
    "# Create save directory\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Check for pre-trained model\n",
    "    if os.path.exists(pretrained_model_path):\n",
    "        logger.info(f\"Loading pre-trained model from {pretrained_model_path}\")\n",
    "        model = YOLO(pretrained_model_path)\n",
    "    else:\n",
    "        logger.info(f\"No pre-trained model found at {pretrained_model_path}. Starting training...\")\n",
    "        # Load and validate data configuration\n",
    "        data_config = load_data_config(data_yaml)\n",
    "        \n",
    "        # Initialize model\n",
    "        logger.info(f\"Loading YOLO model: {model_name}\")\n",
    "        model = YOLO(model_name)\n",
    "        \n",
    "        # Train model\n",
    "        logger.info(\"Starting training...\")\n",
    "        results = model.train(\n",
    "            data=data_yaml,\n",
    "            epochs=epochs,\n",
    "            imgsz=img_size,\n",
    "            batch=batch_size,\n",
    "            device=device,\n",
    "            project=save_dir,\n",
    "            name='yolo12_train',\n",
    "            plots=True,\n",
    "            save_period=10,  # Save checkpoint every 10 epochs\n",
    "            patience=20,     # Early stopping if no improvement\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Plot training metrics\n",
    "        plot_training_metrics(save_dir)\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_metrics = evaluate_model(model, data_yaml, split='val')\n",
    "        \n",
    "        # Evaluate on test set if available\n",
    "        if 'test' in data_config:\n",
    "            test_metrics = evaluate_model(model, data_yaml, split='test')\n",
    "            \n",
    "            # Save results to CSV\n",
    "            results_df = pd.DataFrame({\n",
    "                'Split': ['Validation', 'Test'],\n",
    "                'mAP50': [val_metrics['mAP50'], test_metrics['mAP50']],\n",
    "                'mAP50-95': [val_metrics['mAP50-95'], test_metrics['mAP50-95']],\n",
    "                'Precision': [val_metrics['Precision'], test_metrics['Precision']],\n",
    "                'Recall': [val_metrics['Recall'], test_metrics['Recall']]\n",
    "            })\n",
    "            results_path = os.path.join(save_dir, 'evaluation_results.csv')\n",
    "            results_df.to_csv(results_path, index=False)\n",
    "            logger.info(f\"Evaluation results saved to {results_path}\")\n",
    "        \n",
    "        # Save final model\n",
    "        model.save(os.path.join(save_dir, 'yolo12_trained.pt'))\n",
    "        logger.info(f\"Final model saved to {save_dir}/yolo12_trained.pt\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Pipeline failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on a Single Image\n",
    "\n",
    "Provide the path to a test image below, and the model will perform inference, overlaying detection results (bounding boxes, labels) on the image and displaying it in a new window using the system's default image viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 14:01:17,100 - WARNING - Test image test_image.jpg not found. Please provide a valid image path.\n"
     ]
    }
   ],
   "source": [
    "# Inference configuration\n",
    "test_image_path = \"test_image.jpg\"  # Replace with your test image path\n",
    "\n",
    "# Perform inference\n",
    "if os.path.exists(test_image_path):\n",
    "    perform_inference(model, test_image_path, save_dir)\n",
    "else:\n",
    "    logger.warning(f\"Test image {test_image_path} not found. Please provide a valid image path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The results are saved in the `runs/train/exp_YYYYMMDD_HHMMSS` directory (if training was performed). Check the following:\n",
    "- `training_log_YYYYMMDD_HHMMSS.log`: Detailed training/inference logs\n",
    "- `training_metrics.png`: Training and validation loss/mAP plots (if trained)\n",
    "- `evaluation_results.csv`: Validation and test metrics (if trained and evaluated)\n",
    "- `yolo12_trained.pt`: Trained model weights (if trained)\n",
    "- Annotated inference image (e.g., `test_image.jpg`) in the save directory\n",
    "\n",
    "If a pre-trained model was used, only inference results and logs are generated.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
